{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOLCskqelS7dXx2LdJXLygM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/isaacmenchaca97/EfficientNetB0/blob/main/medical_image_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Digital Image Processing for General Image Classification: Final Project\n",
        "###Isaac Menchaca Panecatl\n",
        "###Dr. Ulises Moya\n",
        "###Computer Science Master's\n",
        "**Based on paper**: [EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks](https://arxiv.org/abs/1905.11946)  (2019), by Mingxing Tan and Quoc V. Le, introduces an innovative approach to scaling convolutional neural networks (CNNs) efficiently and effectively.\n",
        "\n",
        "**Objective**: To develop an image classification system using the pre-trained EfficientNet-B0 model, evaluating the impact of various digital image processing techniques (blur, noise, and contrast) on the model's performance when classifying 100 general images from a selected dataset.\n",
        "\n",
        "**Methodology**:\n",
        "\n",
        "\n",
        "1.   Data Preparation: Select 100 images from a general-purpose dataset.\n",
        "Perform dimensionality preprocessing to standardize the input size for the EfficientNet-B0 model.\n",
        "2.   Baseline Classification: Use the pre-trained EfficientNet-B0 model to classify the original images and record metrics such as accuracy, precision, and recall.\n",
        "1.   Testing with Image Processing:\n",
        "  - Blur: Apply a blur filter (Gaussian Blur) to the images and perform classification using EfficientNet-B0.\n",
        "  - Noise: Add random noise (salt-and-pepper) to the images and repeat the classification.\n",
        "  - Contrast: Enhance image contrast using techniques such as histogram adjustment or CLAHE (Contrast Limited Adaptive Histogram Equalization), then classify the images.\n",
        "2.   Results Analysis: Compare classification metrics across original and processed images.\n",
        "Evaluate how each image processing technique influences the model's performance.\n",
        "1.   Conclusions: Identify which image modifications positively or negatively affect classification accuracy.\n",
        "\n",
        "\n",
        "**Link to video**:"
      ],
      "metadata": {
        "id": "zU8mchE0sboW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1. Data Preparation"
      ],
      "metadata": {
        "id": "IizaemoHvaAM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wcBgkwRUSJm0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fcb9500b-acfd-4ece-e863-dcec50bf8367"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu for inference\n"
          ]
        }
      ],
      "source": [
        "#!/usr/bin/env python\n",
        "## -*- coding: utf-8 -*-\n",
        "__author__ = [\"Isaac Menchaca Panecatl\"]\n",
        "__copyright__ = \"Copyright 2024\"\n",
        "__credits__ = [\"Isaac Menchaca Panecatl\"]\n",
        "__license__ = \"MIT\"\n",
        "__version__ = \"0.0.1\"\n",
        "__maintainer__ = [\"Isaac Menchaca Panecatl\"]\n",
        "__email__ = \"isaac.menchaca@edu.uag.mx\"\n",
        "__status__ = \"Development\"\n",
        "\n",
        "import torch\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "import json\n",
        "import requests\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "%matplotlib inline\n",
        "\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "print(f'Using {device} for inference')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install validators matplotlib"
      ],
      "metadata": {
        "id": "zBrgdBhR2ZCA",
        "outputId": "555c097b-a34d-45ff-ead8-215b960fa1e7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting validators\n",
            "  Downloading validators-0.34.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.8.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.55.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: numpy<2,>=1.21 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Downloading validators-0.34.0-py3-none-any.whl (43 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/43.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: validators\n",
            "Successfully installed validators-0.34.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://images.cocodataset.org/annotations/annotations_trainval2017.zip -O coco_ann2017.zip"
      ],
      "metadata": {
        "id": "cHHuZUVHu3b6",
        "outputId": "7449305b-ccc1-491f-b3ab-0e3baaf7774d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-12-06 02:41:22--  http://images.cocodataset.org/annotations/annotations_trainval2017.zip\n",
            "Resolving images.cocodataset.org (images.cocodataset.org)... 52.216.28.36, 54.231.233.217, 52.217.131.153, ...\n",
            "Connecting to images.cocodataset.org (images.cocodataset.org)|52.216.28.36|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 252907541 (241M) [application/zip]\n",
            "Saving to: ‘coco_ann2017.zip’\n",
            "\n",
            "coco_ann2017.zip    100%[===================>] 241.19M  96.5MB/s    in 2.5s    \n",
            "\n",
            "2024-12-06 02:41:24 (96.5 MB/s) - ‘coco_ann2017.zip’ saved [252907541/252907541]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip coco_ann2017.zip"
      ],
      "metadata": {
        "id": "GN83dzpf1n8o",
        "outputId": "d7181b28-74d0-4430-c7eb-7e58fff237a7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  coco_ann2017.zip\n",
            "  inflating: annotations/instances_train2017.json  \n",
            "  inflating: annotations/instances_val2017.json  \n",
            "  inflating: annotations/captions_train2017.json  \n",
            "  inflating: annotations/captions_val2017.json  \n",
            "  inflating: annotations/person_keypoints_train2017.json  \n",
            "  inflating: annotations/person_keypoints_val2017.json  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pycocotools.coco import COCO\n",
        "import requests\n",
        "\n",
        "# Ruta al archivo de anotaciones (puedes descargarlo desde el sitio de COCO)\n",
        "annFile = 'annotations/instances_val2017.json'\n",
        "\n",
        "# Cargar el archivo de anotaciones\n",
        "coco = COCO(annFile)\n",
        "\n",
        "# Obtener los IDs de las imágenes\n",
        "img_ids = coco.getImgIds()\n",
        "\n",
        "# Generar una lista con las URLs de las imágenes\n",
        "base_url = 'http://images.cocodataset.org/val2017/'  # Cambia según el conjunto de datos\n",
        "\n",
        "uris = []\n",
        "\n",
        "# Obtener las URLs para las primeras 100 imágenes\n",
        "for img_id in img_ids[:100]:\n",
        "    img_info = coco.loadImgs(img_id)[0]\n",
        "    img_url = base_url + img_info['file_name']\n",
        "    uris.append(img_url)\n",
        "\n",
        "# Ver las primeras 10 URLs generadas\n",
        "for uri in uris[:10]:\n",
        "    print(uri)\n"
      ],
      "metadata": {
        "id": "qOZWRriN1qQj",
        "outputId": "b67165f6-759b-4b4b-9317-b1dcb56b6612",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=1.29s)\n",
            "creating index...\n",
            "index created!\n",
            "http://images.cocodataset.org/val2017/000000397133.jpg\n",
            "http://images.cocodataset.org/val2017/000000037777.jpg\n",
            "http://images.cocodataset.org/val2017/000000252219.jpg\n",
            "http://images.cocodataset.org/val2017/000000087038.jpg\n",
            "http://images.cocodataset.org/val2017/000000174482.jpg\n",
            "http://images.cocodataset.org/val2017/000000403385.jpg\n",
            "http://images.cocodataset.org/val2017/000000006818.jpg\n",
            "http://images.cocodataset.org/val2017/000000480985.jpg\n",
            "http://images.cocodataset.org/val2017/000000458054.jpg\n",
            "http://images.cocodataset.org/val2017/000000331352.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "efficientnet = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_efficientnet_b0', pretrained=True)\n",
        "utils = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_convnets_processing_utils')\n",
        "\n",
        "efficientnet.eval().to(device)"
      ],
      "metadata": {
        "id": "wqqSUVmf1hcW",
        "outputId": "7e680a24-36ff-4591-a32f-e1b03d545f26",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/NVIDIA_DeepLearningExamples_torchhub\n",
            "Using cache found in /root/.cache/torch/hub/NVIDIA_DeepLearningExamples_torchhub\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "EfficientNet(\n",
              "  (stem): Sequential(\n",
              "    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "    (activation): SiLU(inplace=True)\n",
              "  )\n",
              "  (layers): Sequential(\n",
              "    (0): Sequential(\n",
              "      (block0): MBConvBlock(\n",
              "        (depsep): Sequential(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (se): SequentialSqueezeAndExcitation(\n",
              "          (squeeze): Linear(in_features=32, out_features=8, bias=True)\n",
              "          (expand): Linear(in_features=8, out_features=32, bias=True)\n",
              "          (activation): SiLU(inplace=True)\n",
              "          (sigmoid): Sigmoid()\n",
              "          (mul_a_quantizer): Identity()\n",
              "          (mul_b_quantizer): Identity()\n",
              "        )\n",
              "        (proj): Sequential(\n",
              "          (conv): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(16, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (residual_quantizer): Identity()\n",
              "      )\n",
              "    )\n",
              "    (1): Sequential(\n",
              "      (block0): MBConvBlock(\n",
              "        (expand): Sequential(\n",
              "          (conv): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (depsep): Sequential(\n",
              "          (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
              "          (bn): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (se): SequentialSqueezeAndExcitation(\n",
              "          (squeeze): Linear(in_features=96, out_features=4, bias=True)\n",
              "          (expand): Linear(in_features=4, out_features=96, bias=True)\n",
              "          (activation): SiLU(inplace=True)\n",
              "          (sigmoid): Sigmoid()\n",
              "          (mul_a_quantizer): Identity()\n",
              "          (mul_b_quantizer): Identity()\n",
              "        )\n",
              "        (proj): Sequential(\n",
              "          (conv): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (residual_quantizer): Identity()\n",
              "      )\n",
              "      (block1): MBConvBlock(\n",
              "        (expand): Sequential(\n",
              "          (conv): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (depsep): Sequential(\n",
              "          (conv): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
              "          (bn): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (se): SequentialSqueezeAndExcitation(\n",
              "          (squeeze): Linear(in_features=144, out_features=6, bias=True)\n",
              "          (expand): Linear(in_features=6, out_features=144, bias=True)\n",
              "          (activation): SiLU(inplace=True)\n",
              "          (sigmoid): Sigmoid()\n",
              "          (mul_a_quantizer): Identity()\n",
              "          (mul_b_quantizer): Identity()\n",
              "        )\n",
              "        (proj): Sequential(\n",
              "          (conv): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (residual_quantizer): Identity()\n",
              "      )\n",
              "    )\n",
              "    (2): Sequential(\n",
              "      (block0): MBConvBlock(\n",
              "        (expand): Sequential(\n",
              "          (conv): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (depsep): Sequential(\n",
              "          (conv): Conv2d(144, 144, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=144, bias=False)\n",
              "          (bn): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (se): SequentialSqueezeAndExcitation(\n",
              "          (squeeze): Linear(in_features=144, out_features=6, bias=True)\n",
              "          (expand): Linear(in_features=6, out_features=144, bias=True)\n",
              "          (activation): SiLU(inplace=True)\n",
              "          (sigmoid): Sigmoid()\n",
              "          (mul_a_quantizer): Identity()\n",
              "          (mul_b_quantizer): Identity()\n",
              "        )\n",
              "        (proj): Sequential(\n",
              "          (conv): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (residual_quantizer): Identity()\n",
              "      )\n",
              "      (block1): MBConvBlock(\n",
              "        (expand): Sequential(\n",
              "          (conv): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (depsep): Sequential(\n",
              "          (conv): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
              "          (bn): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (se): SequentialSqueezeAndExcitation(\n",
              "          (squeeze): Linear(in_features=240, out_features=10, bias=True)\n",
              "          (expand): Linear(in_features=10, out_features=240, bias=True)\n",
              "          (activation): SiLU(inplace=True)\n",
              "          (sigmoid): Sigmoid()\n",
              "          (mul_a_quantizer): Identity()\n",
              "          (mul_b_quantizer): Identity()\n",
              "        )\n",
              "        (proj): Sequential(\n",
              "          (conv): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (residual_quantizer): Identity()\n",
              "      )\n",
              "    )\n",
              "    (3): Sequential(\n",
              "      (block0): MBConvBlock(\n",
              "        (expand): Sequential(\n",
              "          (conv): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (depsep): Sequential(\n",
              "          (conv): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
              "          (bn): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (se): SequentialSqueezeAndExcitation(\n",
              "          (squeeze): Linear(in_features=240, out_features=10, bias=True)\n",
              "          (expand): Linear(in_features=10, out_features=240, bias=True)\n",
              "          (activation): SiLU(inplace=True)\n",
              "          (sigmoid): Sigmoid()\n",
              "          (mul_a_quantizer): Identity()\n",
              "          (mul_b_quantizer): Identity()\n",
              "        )\n",
              "        (proj): Sequential(\n",
              "          (conv): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (residual_quantizer): Identity()\n",
              "      )\n",
              "      (block1): MBConvBlock(\n",
              "        (expand): Sequential(\n",
              "          (conv): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (depsep): Sequential(\n",
              "          (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
              "          (bn): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (se): SequentialSqueezeAndExcitation(\n",
              "          (squeeze): Linear(in_features=480, out_features=20, bias=True)\n",
              "          (expand): Linear(in_features=20, out_features=480, bias=True)\n",
              "          (activation): SiLU(inplace=True)\n",
              "          (sigmoid): Sigmoid()\n",
              "          (mul_a_quantizer): Identity()\n",
              "          (mul_b_quantizer): Identity()\n",
              "        )\n",
              "        (proj): Sequential(\n",
              "          (conv): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (residual_quantizer): Identity()\n",
              "      )\n",
              "      (block2): MBConvBlock(\n",
              "        (expand): Sequential(\n",
              "          (conv): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (depsep): Sequential(\n",
              "          (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
              "          (bn): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (se): SequentialSqueezeAndExcitation(\n",
              "          (squeeze): Linear(in_features=480, out_features=20, bias=True)\n",
              "          (expand): Linear(in_features=20, out_features=480, bias=True)\n",
              "          (activation): SiLU(inplace=True)\n",
              "          (sigmoid): Sigmoid()\n",
              "          (mul_a_quantizer): Identity()\n",
              "          (mul_b_quantizer): Identity()\n",
              "        )\n",
              "        (proj): Sequential(\n",
              "          (conv): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (residual_quantizer): Identity()\n",
              "      )\n",
              "    )\n",
              "    (4): Sequential(\n",
              "      (block0): MBConvBlock(\n",
              "        (expand): Sequential(\n",
              "          (conv): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (depsep): Sequential(\n",
              "          (conv): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
              "          (bn): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (se): SequentialSqueezeAndExcitation(\n",
              "          (squeeze): Linear(in_features=480, out_features=20, bias=True)\n",
              "          (expand): Linear(in_features=20, out_features=480, bias=True)\n",
              "          (activation): SiLU(inplace=True)\n",
              "          (sigmoid): Sigmoid()\n",
              "          (mul_a_quantizer): Identity()\n",
              "          (mul_b_quantizer): Identity()\n",
              "        )\n",
              "        (proj): Sequential(\n",
              "          (conv): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (residual_quantizer): Identity()\n",
              "      )\n",
              "      (block1): MBConvBlock(\n",
              "        (expand): Sequential(\n",
              "          (conv): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (depsep): Sequential(\n",
              "          (conv): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
              "          (bn): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (se): SequentialSqueezeAndExcitation(\n",
              "          (squeeze): Linear(in_features=672, out_features=28, bias=True)\n",
              "          (expand): Linear(in_features=28, out_features=672, bias=True)\n",
              "          (activation): SiLU(inplace=True)\n",
              "          (sigmoid): Sigmoid()\n",
              "          (mul_a_quantizer): Identity()\n",
              "          (mul_b_quantizer): Identity()\n",
              "        )\n",
              "        (proj): Sequential(\n",
              "          (conv): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (residual_quantizer): Identity()\n",
              "      )\n",
              "      (block2): MBConvBlock(\n",
              "        (expand): Sequential(\n",
              "          (conv): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (depsep): Sequential(\n",
              "          (conv): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
              "          (bn): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (se): SequentialSqueezeAndExcitation(\n",
              "          (squeeze): Linear(in_features=672, out_features=28, bias=True)\n",
              "          (expand): Linear(in_features=28, out_features=672, bias=True)\n",
              "          (activation): SiLU(inplace=True)\n",
              "          (sigmoid): Sigmoid()\n",
              "          (mul_a_quantizer): Identity()\n",
              "          (mul_b_quantizer): Identity()\n",
              "        )\n",
              "        (proj): Sequential(\n",
              "          (conv): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (residual_quantizer): Identity()\n",
              "      )\n",
              "    )\n",
              "    (5): Sequential(\n",
              "      (block0): MBConvBlock(\n",
              "        (expand): Sequential(\n",
              "          (conv): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (depsep): Sequential(\n",
              "          (conv): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
              "          (bn): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (se): SequentialSqueezeAndExcitation(\n",
              "          (squeeze): Linear(in_features=672, out_features=28, bias=True)\n",
              "          (expand): Linear(in_features=28, out_features=672, bias=True)\n",
              "          (activation): SiLU(inplace=True)\n",
              "          (sigmoid): Sigmoid()\n",
              "          (mul_a_quantizer): Identity()\n",
              "          (mul_b_quantizer): Identity()\n",
              "        )\n",
              "        (proj): Sequential(\n",
              "          (conv): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (residual_quantizer): Identity()\n",
              "      )\n",
              "      (block1): MBConvBlock(\n",
              "        (expand): Sequential(\n",
              "          (conv): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (depsep): Sequential(\n",
              "          (conv): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
              "          (bn): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (se): SequentialSqueezeAndExcitation(\n",
              "          (squeeze): Linear(in_features=1152, out_features=48, bias=True)\n",
              "          (expand): Linear(in_features=48, out_features=1152, bias=True)\n",
              "          (activation): SiLU(inplace=True)\n",
              "          (sigmoid): Sigmoid()\n",
              "          (mul_a_quantizer): Identity()\n",
              "          (mul_b_quantizer): Identity()\n",
              "        )\n",
              "        (proj): Sequential(\n",
              "          (conv): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (residual_quantizer): Identity()\n",
              "      )\n",
              "      (block2): MBConvBlock(\n",
              "        (expand): Sequential(\n",
              "          (conv): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (depsep): Sequential(\n",
              "          (conv): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
              "          (bn): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (se): SequentialSqueezeAndExcitation(\n",
              "          (squeeze): Linear(in_features=1152, out_features=48, bias=True)\n",
              "          (expand): Linear(in_features=48, out_features=1152, bias=True)\n",
              "          (activation): SiLU(inplace=True)\n",
              "          (sigmoid): Sigmoid()\n",
              "          (mul_a_quantizer): Identity()\n",
              "          (mul_b_quantizer): Identity()\n",
              "        )\n",
              "        (proj): Sequential(\n",
              "          (conv): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (residual_quantizer): Identity()\n",
              "      )\n",
              "      (block3): MBConvBlock(\n",
              "        (expand): Sequential(\n",
              "          (conv): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (depsep): Sequential(\n",
              "          (conv): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
              "          (bn): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (se): SequentialSqueezeAndExcitation(\n",
              "          (squeeze): Linear(in_features=1152, out_features=48, bias=True)\n",
              "          (expand): Linear(in_features=48, out_features=1152, bias=True)\n",
              "          (activation): SiLU(inplace=True)\n",
              "          (sigmoid): Sigmoid()\n",
              "          (mul_a_quantizer): Identity()\n",
              "          (mul_b_quantizer): Identity()\n",
              "        )\n",
              "        (proj): Sequential(\n",
              "          (conv): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (residual_quantizer): Identity()\n",
              "      )\n",
              "    )\n",
              "    (6): Sequential(\n",
              "      (block0): MBConvBlock(\n",
              "        (expand): Sequential(\n",
              "          (conv): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (depsep): Sequential(\n",
              "          (conv): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
              "          (bn): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (se): SequentialSqueezeAndExcitation(\n",
              "          (squeeze): Linear(in_features=1152, out_features=48, bias=True)\n",
              "          (expand): Linear(in_features=48, out_features=1152, bias=True)\n",
              "          (activation): SiLU(inplace=True)\n",
              "          (sigmoid): Sigmoid()\n",
              "          (mul_a_quantizer): Identity()\n",
              "          (mul_b_quantizer): Identity()\n",
              "        )\n",
              "        (proj): Sequential(\n",
              "          (conv): Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(320, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (residual_quantizer): Identity()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (features): Sequential(\n",
              "    (conv): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "    (bn): BatchNorm2d(1280, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "    (activation): SiLU(inplace=True)\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (pooling): AdaptiveAvgPool2d(output_size=1)\n",
              "    (squeeze): Flatten()\n",
              "    (dropout): Dropout(p=0.2, inplace=False)\n",
              "    (fc): Linear(in_features=1280, out_features=1000, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch = torch.cat(\n",
        "    [utils.prepare_input_from_uri(uri) for uri in uris]\n",
        ").to(device)"
      ],
      "metadata": {
        "id": "cnOJhfn311Mn"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2. Baseline Classification"
      ],
      "metadata": {
        "id": "z6k9E0z2Av2e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    output = torch.nn.functional.softmax(efficientnet(batch), dim=1)\n",
        "\n",
        "results = utils.pick_n_best(predictions=output, n=1)"
      ],
      "metadata": {
        "id": "-dzsSJY02AGW",
        "outputId": "8e8bc009-b38b-4181-8f42-08563aa542b2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading Imagenet Classes names.\n",
            "Downloading finished.\n",
            "sample 0: [('shoe shop, shoe-shop, shoe store', '13.7%')]\n",
            "sample 1: [('microwave, microwave oven', '86.5%')]\n",
            "sample 2: [('shopping cart', '11.2%')]\n",
            "sample 3: [('unicycle, monocycle', '86.1%')]\n",
            "sample 4: [('mountain bike, all-terrain bike, off-roader', '63.9%')]\n",
            "sample 5: [('toilet seat', '23.1%')]\n",
            "sample 6: [('toilet tissue, toilet paper, bathroom tissue', '29.0%')]\n",
            "sample 7: [('grille, radiator grille', '30.6%')]\n",
            "sample 8: [('toilet seat', '72.3%')]\n",
            "sample 9: [('toilet seat', '55.8%')]\n",
            "sample 10: [('jinrikisha, ricksha, rickshaw', '20.4%')]\n",
            "sample 11: [('bookshop, bookstore, bookstall', '25.7%')]\n",
            "sample 12: [('prison, prison house', '27.6%')]\n",
            "sample 13: [('television, television system', '43.5%')]\n",
            "sample 14: [('pitcher, ewer', '38.9%')]\n",
            "sample 15: [('solar dish, solar collector, solar furnace', '38.5%')]\n",
            "sample 16: [('basenji', '15.5%')]\n",
            "sample 17: [('park bench', '65.0%')]\n",
            "sample 18: [('ox', '19.2%')]\n",
            "sample 19: [('garbage truck, dustcart', '14.8%')]\n",
            "sample 20: [('moving van', '58.3%')]\n",
            "sample 21: [('cab, hack, taxi, taxicab', '11.8%')]\n",
            "sample 22: [('tow truck, tow car, wrecker', '26.0%')]\n",
            "sample 23: [('trolleybus, trolley coach, trackless trolley', '42.9%')]\n",
            "sample 24: [('street sign', '18.3%')]\n",
            "sample 25: [('street sign', '96.8%')]\n",
            "sample 26: [('gazelle', '7.2%')]\n",
            "sample 27: [('studio couch, day bed', '37.3%')]\n",
            "sample 28: [('Boston bull, Boston terrier', '12.8%')]\n",
            "sample 29: [('street sign', '85.2%')]\n",
            "sample 30: [('peacock', '11.9%')]\n",
            "sample 31: [('passenger car, coach, carriage', '29.8%')]\n",
            "sample 32: [('passenger car, coach, carriage', '50.5%')]\n",
            "sample 33: [('street sign', '5.9%')]\n",
            "sample 34: [('street sign', '55.0%')]\n",
            "sample 35: [('street sign', '69.9%')]\n",
            "sample 36: [('malinois', '26.7%')]\n",
            "sample 37: [('tabby, tabby cat', '25.4%')]\n",
            "sample 38: [('tiger cat', '10.9%')]\n",
            "sample 39: [('bison', '25.5%')]\n",
            "sample 40: [('oxcart', '40.1%')]\n",
            "sample 41: [('television, television system', '32.5%')]\n",
            "sample 42: [('monitor', '28.7%')]\n",
            "sample 43: [('mask', '15.5%')]\n",
            "sample 44: [('groom, bridegroom', '9.7%')]\n",
            "sample 45: [('speedboat', '9.8%')]\n",
            "sample 46: [('African elephant, Loxodonta africana', '56.2%')]\n",
            "sample 47: [('submarine, pigboat, sub, U-boat', '37.1%')]\n",
            "sample 48: [('African elephant, Loxodonta africana', '62.8%')]\n",
            "sample 49: [('umbrella', '60.7%')]\n",
            "sample 50: [('tusker', '43.8%')]\n",
            "sample 51: [('miniskirt, mini', '32.7%')]\n",
            "sample 52: [('Polaroid camera, Polaroid Land camera', '21.4%')]\n",
            "sample 53: [('boxer', '12.4%')]\n",
            "sample 54: [('sleeping bag', '6.6%')]\n",
            "sample 55: [('ice bear, polar bear, Ursus Maritimus, Thalarctos maritimus', '92.1%')]\n",
            "sample 56: [('zebra', '85.4%')]\n",
            "sample 57: [('zebra', '80.3%')]\n",
            "sample 58: [('zebra', '82.9%')]\n",
            "sample 59: [('zebra', '83.8%')]\n",
            "sample 60: [('sorrel', '22.8%')]\n",
            "sample 61: [('horse cart, horse-cart', '32.3%')]\n",
            "sample 62: [('sorrel', '22.8%')]\n",
            "sample 63: [('ski', '61.3%')]\n",
            "sample 64: [('ballplayer, baseball player', '33.5%')]\n",
            "sample 65: [('ski', '53.6%')]\n",
            "sample 66: [('chocolate sauce, chocolate syrup', '36.2%')]\n",
            "sample 67: [('broccoli', '72.0%')]\n",
            "sample 68: [('knee pad', '24.2%')]\n",
            "sample 69: [('unicycle, monocycle', '51.2%')]\n",
            "sample 70: [('ski', '38.5%')]\n",
            "sample 71: [('parachute, chute', '29.2%')]\n",
            "sample 72: [('microphone, mike', '53.5%')]\n",
            "sample 73: [('pretzel', '56.0%')]\n",
            "sample 74: [('hotdog, hot dog, red hot', '11.4%')]\n",
            "sample 75: [('cheeseburger', '38.8%')]\n",
            "sample 76: [('bakery, bakeshop, bakehouse', '33.6%')]\n",
            "sample 77: [('Granny Smith', '18.4%')]\n",
            "sample 78: [('burrito', '19.6%')]\n",
            "sample 79: [('chocolate sauce, chocolate syrup', '23.0%')]\n",
            "sample 80: [('ballplayer, baseball player', '36.8%')]\n",
            "sample 81: [('seashore, coast, seacoast, sea-coast', '29.8%')]\n",
            "sample 82: [('altar', '72.7%')]\n",
            "sample 83: [('soccer ball', '90.7%')]\n",
            "sample 84: [('candle, taper, wax light', '89.8%')]\n",
            "sample 85: [('folding chair', '74.4%')]\n",
            "sample 86: [('wardrobe, closet, press', '17.2%')]\n",
            "sample 87: [('ice cream, icecream', '20.4%')]\n",
            "sample 88: [('soccer ball', '76.8%')]\n",
            "sample 89: [('four-poster', '55.6%')]\n",
            "sample 90: [('stretcher', '23.4%')]\n",
            "sample 91: [('pizza, pizza pie', '40.3%')]\n",
            "sample 92: [('speedboat', '52.4%')]\n",
            "sample 93: [('quilt, comforter, comfort, puff', '24.9%')]\n",
            "sample 94: [('studio couch, day bed', '53.1%')]\n",
            "sample 95: [('bakery, bakeshop, bakehouse', '30.5%')]\n",
            "sample 96: [('pizza, pizza pie', '63.0%')]\n",
            "sample 97: [('rocking chair, rocker', '37.6%')]\n",
            "sample 98: [('pizza, pizza pie', '27.2%')]\n",
            "sample 99: [('racket, racquet', '25.3%')]\n"
          ]
        }
      ]
    }
  ]
}